{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SWE-agent","text":"<p>SWE-agent turns LMs (e.g. GPT-4) into software engineering agents that can fix bugs and issues in real GitHub repositories.</p> <p>On SWE-bench, SWE-agent resolves 12.29% of issues, achieving the state-of-the-art performance on the full test set.</p> <p>We accomplish our results by designing simple LM-centric commands and feedback formats to make it easier for the LM to browse the repository, view, edit and execute code files. We call this an \ud83e\udd16 Agent-Computer Interface (ACI). Read more about it in our paper!</p> <p>SWE-agent is built and maintained by researchers from Princeton University. </p> <p> </p> <p>If you found this work helpful, please consider using the following citation:</p> <pre><code>@misc{yang2024sweagent,\n      title={SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering}, \n      author={John Yang and Carlos E. Jimenez and Alexander Wettig and Kilian Lieret and Shunyu Yao and Karthik Narasimhan and Ofir Press},\n      year={2024},\n}\n</code></pre>"},{"location":"#use-swe-agent-as-a-dev-tool","title":"\u2728 Use SWE-agent as a dev tool","text":"<p>We provide a command line tool and a graphical web interface:</p> <p></p>"},{"location":"modify/","title":"Modifying the behavior of SWE-agent","text":""},{"location":"modify/#code-structure","title":"Code structure","text":"<ul> <li>See the <code>scripts/</code> folder for other useful scripts and details.</li> <li>See the <code>config/</code> folder for details about how you can define your own configuration!</li> <li>See the <code>sweagent/agent/</code> folder for details about the logic behind configuration based workflows.</li> <li>See the <code>sweagent/environment/</code> folder for details about the <code>SWEEnv</code> environment (interface + implementation).</li> <li>See the <code>trajectories/</code> folder for details about the output of <code>run.py</code>.</li> <li>See the <code>evaluation/</code> folder for details about how evaluation works.</li> </ul>"},{"location":"modify/#changing-the-demonstrations","title":"Changing the demonstrations","text":"<p>If you'd like to modify the example demonstration that we feed the model at the start of each run, first generate a trajectory manually by running the agent with <code>--model_name human</code>  and then convert that trajectory into a demonstration by following the guide here. </p> <p>To edit text in <code>human</code> mode:</p> <ol> <li>Run the command <code>edit edit_start_line:edit_end_line</code></li> <li>Write the text you want to insert. Feel free to write the text across multiple lines. </li> <li>Press <code>return</code> then write <code>end_of_edit</code> and then press <code>return</code> again to submit the edit.</li> </ol>"},{"location":"installation/","title":"Setting up SWE-agent","text":"<p>We currently offer three options:</p> <ol> <li> <p>Run SWE-agent completely in your browser: This is done using GitHub pages, basically a VSCode environment that runs in your browser. All necessary packages will be pre-installed, so you can get started directly. Read more here.</p> </li> <li> <p>Local installation: Install SWE-agent from source using <code>pip</code>. Read more here.</p> </li> <li> <p>Fully containerized deployment using docker: Pull a docker container and directly run SWE-agent. This is our fallback solution if the local installation does not work for you. Read more here.</p> </li> </ol>"},{"location":"installation/codespaces/","title":"Running SWE-agent in your browser","text":"<ol> <li>Click </li> <li>Add your API keys to <code>keys.cfg</code> (find the file in the left sidebar and fill out the template). More information on the keys here.</li> <li>Make sure to wait until the <code>postCreateCommand</code> in the terminal window at the bottom is finished</li> <li>Enter your SWE-agent command, see using the web interface or using the command line.</li> </ol>"},{"location":"installation/codespaces/#running-the-web-ui","title":"Running the Web UI","text":"<p>Go to the terminal and enter</p> <pre><code>./start_web_ui.sh\n</code></pre> <p>After a while, you should see a popup offering you to forward port <code>3000</code>. Click <code>Open in Browser</code>.</p> <p></p> <p>If you instead only see the offer to forward port <code>8000</code>, do not click it (this is the port that's being used by the backend).</p> <p>Instead, click on the <code>Ports</code> tab, and click on the globe next to port <code>3000</code>:</p> <p></p>"},{"location":"installation/docker/","title":"Fallback: Usage with docker","text":"<p>Limitations</p> <p>The latest containerized version does not yet provide the web interface.</p> <p>Instead of installing SWE-agent from source, you can also run the software directly using Docker. </p> <ol> <li>Install Docker, then start Docker locally.</li> <li>Run <code>docker pull sweagent/swe-agent:latest</code></li> <li>Add your API tokens to a file <code>keys.cfg</code> as explained here</li> </ol> <p>Then run</p> <pre><code># NOTE:\n# This assumes that keys.cfg is in your current directory (else fix the path below)\n# This command is equivalent to the script shown in the quickstart \ndocker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v $(pwd)/keys.cfg:/app/keys.cfg \\\n  sweagent/swe-agent-run:latest \\\n  python run.py --image_name=sweagent/swe-agent:latest \\\n  --model_name gpt4 \\\n  --data_path https://github.com/pvlib/pvlib-python/issues/1603 \\\n  --config_file config/default_from_url.yaml  --skip_existing=False\n</code></pre> <p>Tips</p> <ul> <li>For more information on the different API keys/tokens, see below.</li> <li>If you're using docker on Windows, use <code>-v //var/run/docker.sock:/var/run/docker.sock</code> (double slash) to escape it (more information).</li> <li>See the installation issues section for more help if you run into trouble.</li> </ul>"},{"location":"installation/keys/","title":"Adding your API keys","text":"<p>Create a <code>keys.cfg</code> file at the root of this repository and populate it with your API keys.</p> <pre><code>GITHUB_TOKEN: 'GitHub Token for access to private repos'  # &lt;-- delete line if not used\nOPENAI_API_KEY: 'OpenAI API Key Here if using OpenAI Model'\nANTHROPIC_API_KEY: 'Anthropic API Key Here if using Anthropic Model'\nTOGETHER_API_KEY: 'Together API Key Here if using Together Model'\nAZURE_OPENAI_API_KEY: 'Azure OpenAI API Key Here if using Azure OpenAI Model'\nAZURE_OPENAI_ENDPOINT: 'Azure OpenAI Endpoint Here if using Azure OpenAI Model'\nAZURE_OPENAI_DEPLOYMENT: 'Azure OpenAI Deployment Here if using Azure OpenAI Model'\nAZURE_OPENAI_API_VERSION: 'Azure OpenAI API Version Here if using Azure OpenAI Model'\nOPENAI_API_BASE_URL: 'LM base URL here if using Local or alternative api Endpoint'\n</code></pre> <p>See the following links for tutorials on obtaining Anthropic, OpenAI, and Github tokens.</p>"},{"location":"installation/source/","title":"Installation from source","text":"<p>Issues on Windows</p> <p>Expect some issues with Windows (we're working on them). In the meantime, use Docker (see below).</p> <ol> <li>Install Docker, then start Docker locally.</li> <li>For the web interface only: Install <code>nodejs</code>.</li> <li>Clone this repository.</li> <li>Run <code>pip install --editable .</code> at the repository root (as with any python setup, it's recommended to use conda or virtual environments to manage dependencies).</li> <li>Run <code>./setup.sh</code> to create the <code>swe-agent</code> docker image.</li> <li>Create a <code>keys.cfg</code> file at the root of this repository (more information).</li> </ol> <p>Docker issues</p> <p>If you run into docker issues, see the installation tips section for more help</p>"},{"location":"installation/tips/","title":"More installation tips","text":"<p>If you seem to be having issues with running docker</p> <ul> <li>Make sure that you allow the use of the Docker socket. In Docker desktop, click Settings &gt; Advanced &gt; Allow the default Docker socket to be used (requires password)</li> <li>If your docker installation uses a different socket, you might have to symlink them, see this command for example</li> </ul> <p>Any remaining issues? Please open a GitHub issue!</p>"},{"location":"usage/","title":"Usage","text":"<p>We currently provide two interfaces to SWE-agent: The command line interface (CLI) and our graphical web interface. </p> <p>While the latter is more beginner-friendly, the CLI currently still has more expert options.</p>"},{"location":"usage/benchmarking/","title":"Benchmarking","text":"<p>There are two steps to the SWE-agent pipeline. First SWE-agent takes an input GitHub issue and returns a pull request that attempts to fix it. We call that step inference. The second step (currently, only available for issues in the SWE-bench benchmark) is to evaluate the pull request to verify that it has indeed fixed the issue. </p> <p>Architectures</p> <p>At this moment, there are known issues with a small number of repositories that don't install properly for <code>arm64</code> / <code>aarch64</code> architecture computers. We're working on a fix, but if you'd like to run and evaluate on the entirety of SWE-bench, the easiest way is by using an <code>x86</code> machine.</p>"},{"location":"usage/benchmarking/#inference","title":"\ud83d\udc69\u200d\ud83d\udcbb Inference","text":"<p>Inference on any GitHub Issue: See above.</p> <p>Inference on SWE-bench: Run SWE-agent on SWE-bench Lite and generate patches.</p> <pre><code>python run.py --model_name gpt4 \\\n  --per_instance_cost_limit 2.00 \\\n  --config_file ./config/default.yaml\n</code></pre> <p>If you'd like to run on a single issue from SWE-bench, use the <code>--instance_filter</code> option as follows: <pre><code>python run.py --model_name gpt4 \\\n  --instance_filter marshmallow-code__marshmallow-1359\n</code></pre></p>"},{"location":"usage/benchmarking/#evaluation","title":"\ud83e\uddea Evaluation","text":"<p>This step is only available for issues from the SWE-bench set. To evaluate generated pull requests: <pre><code>cd evaluation/\n./run_eval.sh &lt;predictions_path&gt;\n</code></pre> Replace <code>&lt;predictions_path&gt;</code> with the path to the model's predictions, which should be generated from the Inference step. The <code>&lt;predictions_path&gt;</code> arguments should look like <code>../trajectories/&lt;username&gt;/&lt;model&gt;-&lt;dataset&gt;-&lt;hyperparams&gt;/all_preds.jsonl</code> * See the <code>evaluation/</code> folder for details about how evaluation works.</p>"},{"location":"usage/cl_tutorial/","title":"Command line usage tutorial","text":"<p>This tutorial walks you trough running SWE-agent from the command line. Beginners might also be interested in the our web-based GUI (see here). This tutorial focuses on using SWE-agent as a tool to solve individual issues. Benchmarking SWE-agent is covered separately.</p>"},{"location":"usage/cl_tutorial/#getting-started","title":"Getting started","text":"<p>For the CLI, use the <code>run.py</code> script. Let's start with an absolutely trivial example and solve an issue about a simple syntax error (<code>swe-agent/test-repo #1</code>)</p> <pre><code>python run.py \\\n  --model_name gpt4 \\\n  --data_path https://github.com/SWE-agent/test-repo/issues/1 \\\n  --config_file config/default_from_url.yaml \\\n  --per_instance_cost_limit 2.00 \n</code></pre> <p>Here, </p> <ul> <li><code>--model_name</code> sets the language model that is used by SWE-agent (with <code>gpt4</code> being the default). More information on the available models in our FAQ</li> <li><code>--data_path</code> points to the source of the problem statement (for example, the GitHub issue that you want to solve). You can also point it to local files (see below)</li> <li><code>--config_file</code> includes settings such as the prompts. Changing the config file is the easiest way to get started with modifying SWE-agent (more advanced options are discussed here).</li> <li><code>--per_instance_cost_limit</code> limits the total inference cost to $2 (default is $3).</li> </ul> <p>All options</p> <ul> <li>Run <code>python run.py --help</code> to see all available options for <code>run.py</code>. This tutorial will only cover a subset of options.</li> <li>If you run the same command more than once, you will find that SWE-agent aborts with <code>Skipping existing trajectory</code>. You can either remove the trajectory from the warning message, or add the <code>--skip_existing=False</code> flag.</li> </ul>"},{"location":"usage/cl_tutorial/#specifying-the-repository","title":"Specifying the repository","text":"<p>In the above example, the repository/codebase is inferred from the <code>--data_path</code>.  This options is currently only available for GitHub issues.  For all other use cases, you can specify <code>--repo_path</code>, which accepts either GitHub URLs or paths to local repositories.</p> <p>To try it out, let's clone the test repository from the previous section.</p> <pre><code>git clone git@github.com:SWE-agent/test-repo.git\n</code></pre> <p>and then run</p> <pre><code>python run.py \\\n  --model_name gpt4 \\\n  --data_path /path/to/test-repo/problem_statements/1.md \\\n  --repo_path /path/to/test-repo \\\n  --config_file config/default_from_url.yaml \\\n  --per_instance_cost_limit 2.00 \\\n  --apply_patch_locally\n</code></pre> <p>where you replaced paths with the prefix <code>/path/to/.../</code> with the actual paths to the corresponding file/directory.</p> <p>We have also added a new flag, <code>--apply_patch_locally</code>, which will make SWE-agent apply the changes to the local repository (if it believes that it has successfully solved the issue).</p> <p>You can mix and match the different ways of specifying problem statements and repositories. For example, any of the following combination of options also works</p> <ul> <li>Local problem statement with GitHub repository (<code>--data_path /path/to/problem.md --repo_path https://github.com/...</code>): Let SWE-agent work on something that wasn't reported yet</li> <li>GitHub issue with local repository (<code>--data_path https://github.com/.../issues/.. --repo_path /path/to/... --apply_patch_locally</code>): Let SWE-agent solve a GitHub issue locally (for example to edit the solution afterwards)</li> <li>GitHub issue with different GitHub repository: Useful with the <code>--open_pr</code> flag (see below) when working from a fork.</li> </ul> <p>In addition, if <code>--repo_path</code> points to a GitHub repository, you can use <code>--base_commit</code> to specify</p> <ul> <li>A branch name (e.g., <code>dev</code>),</li> <li>A tag (e.g., <code>v1.0.0</code>),</li> <li>A commit hash (e.g., <code>a4464baca1f28d7733337df6e4daa6c1ed920336</code>).</li> </ul> <p>SWE-agent will then start from this commit when trying to solve the problem.</p> <p>Uncommitted changes</p> <p>When running with a local <code>--repo_path</code>, SWE-agent will use the last commit, i.e., all local, uncommitted changes will not be seen by SWE-agent.</p>"},{"location":"usage/cl_tutorial/#installing-dependencies-and-setting-up-the-environment","title":"Installing dependencies and setting up the environment","text":"<p>Now let's move on to a slightly more complicated issue (<code>swe-agent/test-repo #22</code>). </p> <p>What makes it more complicated? This time the problematic code is part of a library <code>testpkg</code>, so SWE-agent first has to install the package in order to reproduce the issue before searching for the problematic code.</p> <p>In most circumstances, GPT4 will attempt to install the package and requirements (usually with some form of <code>pip install .</code> or <code>pip install pkg</code>). However, this wastes valuable queries to the LM. In addition, you might need to run your software for a specific python version or have other specific environment settings. The <code>--environment_setup</code> flag is used to fix this problem.</p> <p>Let's try it:</p> <pre><code>python run.py \\\n  --data_path https://github.com/SWE-agent/test-repo/issues/22 \\\n  --config_file config/default_from_url.yaml \\\n  --environment_setup config/environment_setup/py310_default.yaml\n</code></pre> <p>This time, <code>pip install -e .</code> is called before SWE-agent gets to work, installing the package defined in the repository.</p> <p>Let's take a look at the config file</p> <pre><code>python: '3.10'\ninstall: 'pip install -e .'\n</code></pre> <p>Here, <code>install</code> is an arbitrary command that is run, while <code>python</code> will be the python version that is setup with conda.</p> <p>The config file also provides two more top level directives:</p> <ul> <li><code>packages</code>: Path to a <code>requirements.txt</code> or to a <code>env.yml</code> as readable by conda</li> <li><code>pip_packages</code>: A list of python packages that are installed with <code>pip install PACKAGE</code></li> </ul>"},{"location":"usage/cl_tutorial/#taking-actions","title":"Taking actions","text":"<ul> <li>As mentioned above, you can use <code>--apply_patch_locally</code> to have SWE-agent apply successful solution attempts to local files.</li> <li>Alternatively, when running on a GitHub issue, you can have the agent automatically open a PR if the issue has been solved by supplying the <code>--open_pr</code> flag.    Please use this feature responsibly (on your own repositories or after careful consideration).</li> </ul> <p>Alternatively, you can always retrieve the patch that was generated by SWE-agent.  Watch out for the followoing message in the log:</p> <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udf89 Submission successful \ud83c\udf89 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 SWE-agent has produced a patch that it believes will solve the issue you submitted! \u2502\n\u2502 Use the code snippet below to inspect or apply it!                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>And follow the instructions below it:</p> <pre><code> # The patch has been saved to your local filesystem at:\n PATCH_FILE_PATH='/Users/.../patches/05917d.patch'\n # Inspect it:\n cat \"${PATCH_FILE_PATH}\"\n # Apply it to a local repository:\n cd &lt;your local repo root&gt;\n git apply \"${PATCH_FILE_PATH}\"\n</code></pre>"},{"location":"usage/faq/","title":"FAQ","text":""},{"location":"usage/faq/#what-models-are-supported","title":"What models are supported?","text":"<p>Models are configured in <code>models.py</code> (we're working on giving a complete list of model settings).</p> <p>Here are some few examples:</p> <pre><code>gpt4\ngpt4o\ngpt4-turbo\nclaude-2\nclaude-opus\nclaude-sonnet\nclaude-haiku\n</code></pre>"},{"location":"usage/faq/#ollama-support","title":"Ollama support","text":"<p>Models served with an ollama server can be used by specifying <code>--model</code> with <code>ollama:model_name</code> and <code>--host_url</code> to point to the url used to serve ollama (<code>http://localhost:11434</code> by default). See more details about using ollama here.</p> <pre><code>python run.py --model_name ollama:deepseek-coder:6.7b-instruct \\\n  --host_url http://localhost:11434 \\\n  --data_path https://github.com/pvlib/pvlib-python/issues/1603 \\\n  --config_file config/default_from_url.yaml\n</code></pre>"},{"location":"usage/faq/#models-for-testing","title":"Models for testing","text":"<p>We also provide models for testing SWE-agent without spending any credits</p> <ul> <li><code>HumanModel</code> and <code>HumandThoughtModel</code> will prompt for input from the user that stands in for the output of the LM</li> <li><code>ReplayModel</code> takes a trajectory as input and \"replays it\"</li> <li><code>InstantEmptySubmitTestModel</code> will create an empty <code>reproduce.py</code> and then submit </li> </ul>"},{"location":"usage/web_ui/","title":"Using the web interface","text":"<p>To start our web UI, simply run</p> <pre><code>./start_web_ui.sh\n</code></pre> <p>from the root of the repository.</p> <p>If the user interface doesn't automatically open in your browser, please open it at <code>http://localhost:3000</code>.</p> <p>Limitations</p> <p>Currently, the web interface only has a subset of the options of the command line interface (CLI). </p>"}]}